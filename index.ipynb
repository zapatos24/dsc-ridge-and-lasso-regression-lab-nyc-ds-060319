{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge and Lasso Regression - Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you'll practice your knowledge on Ridge and Lasso regression!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will be able to:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use Lasso and ridge regression in Python\n",
    "- Compare Lasso and Ridge with standard regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Housing Prices Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at yet another house pricing data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df = pd.read_csv('Housing_Prices/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 81 columns):\n",
      "Id               1460 non-null int64\n",
      "MSSubClass       1460 non-null int64\n",
      "MSZoning         1460 non-null object\n",
      "LotFrontage      1201 non-null float64\n",
      "LotArea          1460 non-null int64\n",
      "Street           1460 non-null object\n",
      "Alley            91 non-null object\n",
      "LotShape         1460 non-null object\n",
      "LandContour      1460 non-null object\n",
      "Utilities        1460 non-null object\n",
      "LotConfig        1460 non-null object\n",
      "LandSlope        1460 non-null object\n",
      "Neighborhood     1460 non-null object\n",
      "Condition1       1460 non-null object\n",
      "Condition2       1460 non-null object\n",
      "BldgType         1460 non-null object\n",
      "HouseStyle       1460 non-null object\n",
      "OverallQual      1460 non-null int64\n",
      "OverallCond      1460 non-null int64\n",
      "YearBuilt        1460 non-null int64\n",
      "YearRemodAdd     1460 non-null int64\n",
      "RoofStyle        1460 non-null object\n",
      "RoofMatl         1460 non-null object\n",
      "Exterior1st      1460 non-null object\n",
      "Exterior2nd      1460 non-null object\n",
      "MasVnrType       1452 non-null object\n",
      "MasVnrArea       1452 non-null float64\n",
      "ExterQual        1460 non-null object\n",
      "ExterCond        1460 non-null object\n",
      "Foundation       1460 non-null object\n",
      "BsmtQual         1423 non-null object\n",
      "BsmtCond         1423 non-null object\n",
      "BsmtExposure     1422 non-null object\n",
      "BsmtFinType1     1423 non-null object\n",
      "BsmtFinSF1       1460 non-null int64\n",
      "BsmtFinType2     1422 non-null object\n",
      "BsmtFinSF2       1460 non-null int64\n",
      "BsmtUnfSF        1460 non-null int64\n",
      "TotalBsmtSF      1460 non-null int64\n",
      "Heating          1460 non-null object\n",
      "HeatingQC        1460 non-null object\n",
      "CentralAir       1460 non-null object\n",
      "Electrical       1459 non-null object\n",
      "1stFlrSF         1460 non-null int64\n",
      "2ndFlrSF         1460 non-null int64\n",
      "LowQualFinSF     1460 non-null int64\n",
      "GrLivArea        1460 non-null int64\n",
      "BsmtFullBath     1460 non-null int64\n",
      "BsmtHalfBath     1460 non-null int64\n",
      "FullBath         1460 non-null int64\n",
      "HalfBath         1460 non-null int64\n",
      "BedroomAbvGr     1460 non-null int64\n",
      "KitchenAbvGr     1460 non-null int64\n",
      "KitchenQual      1460 non-null object\n",
      "TotRmsAbvGrd     1460 non-null int64\n",
      "Functional       1460 non-null object\n",
      "Fireplaces       1460 non-null int64\n",
      "FireplaceQu      770 non-null object\n",
      "GarageType       1379 non-null object\n",
      "GarageYrBlt      1379 non-null float64\n",
      "GarageFinish     1379 non-null object\n",
      "GarageCars       1460 non-null int64\n",
      "GarageArea       1460 non-null int64\n",
      "GarageQual       1379 non-null object\n",
      "GarageCond       1379 non-null object\n",
      "PavedDrive       1460 non-null object\n",
      "WoodDeckSF       1460 non-null int64\n",
      "OpenPorchSF      1460 non-null int64\n",
      "EnclosedPorch    1460 non-null int64\n",
      "3SsnPorch        1460 non-null int64\n",
      "ScreenPorch      1460 non-null int64\n",
      "PoolArea         1460 non-null int64\n",
      "PoolQC           7 non-null object\n",
      "Fence            281 non-null object\n",
      "MiscFeature      54 non-null object\n",
      "MiscVal          1460 non-null int64\n",
      "MoSold           1460 non-null int64\n",
      "YrSold           1460 non-null int64\n",
      "SaleType         1460 non-null object\n",
      "SaleCondition    1460 non-null object\n",
      "SalePrice        1460 non-null int64\n",
      "dtypes: float64(3), int64(35), object(43)\n",
      "memory usage: 924.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, make a selection of the data by removing some of the data with `dtype = object`, this way our first model only contains **continuous features**\n",
    "\n",
    "Make sure to remove the SalesPrice column from the predictors (which you store in `X`), then replace missing inputs by the median per feature.\n",
    "\n",
    "Store the target in `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary packages\n",
    "from sklearn.linear_model import Lasso, Ridge, LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# remove \"object\"-type features and SalesPrice from `X`\n",
    "X = df.drop([col for col in list(df.columns) if df[col].dtype == 'object'], axis=1)\n",
    "X.drop('SalePrice', axis=1, inplace=True)\n",
    "\n",
    "# Impute null values\n",
    "X.LotFrontage.fillna(X.LotFrontage.dropna().median(), inplace=True)\n",
    "X.GarageYrBlt.fillna(X.GarageYrBlt.dropna().median(), inplace=True)\n",
    "X.MasVnrArea.fillna(X.MasVnrArea.dropna().median(), inplace=True)\n",
    "# Create y\n",
    "y = df.SalePrice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the information of `X` again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 37 columns):\n",
      "Id               1460 non-null int64\n",
      "MSSubClass       1460 non-null int64\n",
      "LotFrontage      1460 non-null float64\n",
      "LotArea          1460 non-null int64\n",
      "OverallQual      1460 non-null int64\n",
      "OverallCond      1460 non-null int64\n",
      "YearBuilt        1460 non-null int64\n",
      "YearRemodAdd     1460 non-null int64\n",
      "MasVnrArea       1460 non-null float64\n",
      "BsmtFinSF1       1460 non-null int64\n",
      "BsmtFinSF2       1460 non-null int64\n",
      "BsmtUnfSF        1460 non-null int64\n",
      "TotalBsmtSF      1460 non-null int64\n",
      "1stFlrSF         1460 non-null int64\n",
      "2ndFlrSF         1460 non-null int64\n",
      "LowQualFinSF     1460 non-null int64\n",
      "GrLivArea        1460 non-null int64\n",
      "BsmtFullBath     1460 non-null int64\n",
      "BsmtHalfBath     1460 non-null int64\n",
      "FullBath         1460 non-null int64\n",
      "HalfBath         1460 non-null int64\n",
      "BedroomAbvGr     1460 non-null int64\n",
      "KitchenAbvGr     1460 non-null int64\n",
      "TotRmsAbvGrd     1460 non-null int64\n",
      "Fireplaces       1460 non-null int64\n",
      "GarageYrBlt      1460 non-null float64\n",
      "GarageCars       1460 non-null int64\n",
      "GarageArea       1460 non-null int64\n",
      "WoodDeckSF       1460 non-null int64\n",
      "OpenPorchSF      1460 non-null int64\n",
      "EnclosedPorch    1460 non-null int64\n",
      "3SsnPorch        1460 non-null int64\n",
      "ScreenPorch      1460 non-null int64\n",
      "PoolArea         1460 non-null int64\n",
      "MiscVal          1460 non-null int64\n",
      "MoSold           1460 non-null int64\n",
      "YrSold           1460 non-null int64\n",
      "dtypes: float64(3), int64(34)\n",
      "memory usage: 422.1 KB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's use this data to perform a first naive linear regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the R squared and the MSE for both train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Train: 0.8508149394655694\n",
      "MSE Train: 1016603870.6482387\n",
      "\n",
      "R2 Test: 0.49605696423712076\n",
      "MSE Test: 2408670072.715824\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error, r2_score\n",
    "\n",
    "# Split in train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "# Fit the model and print R2 and MSE for train and test\n",
    "lin = LinearRegression()\n",
    "lin.fit(X_train, y_train)\n",
    "\n",
    "r2_train = r2_score(y_train, lin.predict(X_train))\n",
    "mse_train = mean_squared_error(y_train, lin.predict(X_train))\n",
    "\n",
    "r2_test = r2_score(y_test, lin.predict(X_test))\n",
    "mse_test = mean_squared_error(y_test, lin.predict(X_test))\n",
    "\n",
    "print('R2 Train: {}\\nMSE Train: {}\\n'.format(r2_train, mse_train))\n",
    "print('R2 Test: {}\\nMSE Test: {}'.format(r2_test, mse_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize your data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We haven't normalized our data, let's create a new model that uses `preprocessing.scale` to scale our predictors!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# Scale the data and perform train test split\n",
    "transformed = preprocessing.scale(X)\n",
    "X = pd.DataFrame(transformed, columns = X.columns)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the same linear regression on this data and print out R-squared and MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Train: 0.8159543522240756\n",
      "MSE Train: 1172370130.7166448\n",
      "\n",
      "R2 Test: 0.7911321409501595\n",
      "MSE Test: 1274556066.8671708\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "lin = LinearRegression()\n",
    "lin.fit(X_train, y_train)\n",
    "\n",
    "r2_train = r2_score(y_train, lin.predict(X_train))\n",
    "mse_train = mean_squared_error(y_train, lin.predict(X_train))\n",
    "\n",
    "r2_test = r2_score(y_test, lin.predict(X_test))\n",
    "mse_test = mean_squared_error(y_test, lin.predict(X_test))\n",
    "\n",
    "print('R2 Train: {}\\nMSE Train: {}\\n'.format(r2_train, mse_train))\n",
    "print('R2 Test: {}\\nMSE Test: {}'.format(r2_test, mse_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Include dummy variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your model hasn't included dummy variables so far: let's use the \"object\" variables again and create dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X_cat which contains only the categorical variables\n",
    "X_cat = df.drop([col for col in list(df.columns) if df[col].dtype != 'object'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dummies\n",
    "X_cat = pd.get_dummies(X_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge `x_cat` together with our scaled `X` so you have one big predictor dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "X_full = pd.concat([X, X_cat], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the same linear regression on this data and print out R-squared and MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Train: 0.9328972187094093\n",
      "MSE Train: 381323369.1022831\n",
      "\n",
      "R2 Test: -1.9959881743844896e+21\n",
      "MSE Test: 1.6231172092577727e+31\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_full, y)\n",
    "\n",
    "lin = LinearRegression()\n",
    "lin.fit(X_train, y_train)\n",
    "\n",
    "r2_train = r2_score(y_train, lin.predict(X_train))\n",
    "mse_train = mean_squared_error(y_train, lin.predict(X_train))\n",
    "\n",
    "r2_test = r2_score(y_test, lin.predict(X_test))\n",
    "mse_test = mean_squared_error(y_test, lin.predict(X_test))\n",
    "\n",
    "print('R2 Train: {}\\nMSE Train: {}\\n'.format(r2_train, mse_train))\n",
    "print('R2 Test: {}\\nMSE Test: {}'.format(r2_test, mse_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the severe overfitting above; our training R squared is quite high, but the testing R squared is negative! Our predictions are far off. Similarly, the scale of the Testing MSE is orders of magnitude higher than that of the training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Ridge and Lasso regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use all the data (normalized features and dummy categorical variables) and perform Lasso and Ridge regression for both! Each time, look at R-squared and MSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With default parameter (alpha = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Train: 0.9487853986215966\n",
      "MSE Train: 291035989.4066221\n",
      "\n",
      "R2 Test: 0.824955239220053\n",
      "MSE Test: 1423446126.878766\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "lasso = Lasso(alpha=1)\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "r2_train = r2_score(y_train, lasso.predict(X_train))\n",
    "mse_train = mean_squared_error(y_train, lasso.predict(X_train))\n",
    "\n",
    "r2_test = r2_score(y_test, lasso.predict(X_test))\n",
    "mse_test = mean_squared_error(y_test, lasso.predict(X_test))\n",
    "\n",
    "print('R2 Train: {}\\nMSE Train: {}\\n'.format(r2_train, mse_train))\n",
    "print('R2 Test: {}\\nMSE Test: {}'.format(r2_test, mse_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a higher regularization parameter (alpha = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Train: 0.9471750421563708\n",
      "MSE Train: 300187123.54689443\n",
      "\n",
      "R2 Test: 0.8321990029645165\n",
      "MSE Test: 1364540579.519689\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "lasso = Lasso(alpha=10)\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "r2_train = r2_score(y_train, lasso.predict(X_train))\n",
    "mse_train = mean_squared_error(y_train, lasso.predict(X_train))\n",
    "\n",
    "r2_test = r2_score(y_test, lasso.predict(X_test))\n",
    "mse_test = mean_squared_error(y_test, lasso.predict(X_test))\n",
    "\n",
    "print('R2 Train: {}\\nMSE Train: {}\\n'.format(r2_train, mse_train))\n",
    "print('R2 Test: {}\\nMSE Test: {}'.format(r2_test, mse_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With default parameter (alpha = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Train: 0.9350140404770928\n",
      "MSE Train: 369294156.71022874\n",
      "\n",
      "R2 Test: 0.8132270730648443\n",
      "MSE Test: 1518818376.8943455\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "ridge = Ridge(alpha=1)\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "r2_train = r2_score(y_train, ridge.predict(X_train))\n",
    "mse_train = mean_squared_error(y_train, ridge.predict(X_train))\n",
    "\n",
    "r2_test = r2_score(y_test, ridge.predict(X_test))\n",
    "mse_test = mean_squared_error(y_test, ridge.predict(X_test))\n",
    "\n",
    "print('R2 Train: {}\\nMSE Train: {}\\n'.format(r2_train, mse_train))\n",
    "print('R2 Test: {}\\nMSE Test: {}'.format(r2_test, mse_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With default parameter (alpha = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Train: 0.9179677914960495\n",
      "MSE Train: 466162467.7845314\n",
      "\n",
      "R2 Test: 0.7975575439364618\n",
      "MSE Test: 1646241388.2911267\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "ridge = Ridge(alpha=10)\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "r2_train = r2_score(y_train, ridge.predict(X_train))\n",
    "mse_train = mean_squared_error(y_train, ridge.predict(X_train))\n",
    "\n",
    "r2_test = r2_score(y_test, ridge.predict(X_test))\n",
    "mse_test = mean_squared_error(y_test, ridge.predict(X_test))\n",
    "\n",
    "print('R2 Train: {}\\nMSE Train: {}\\n'.format(r2_train, mse_train))\n",
    "print('R2 Test: {}\\nMSE Test: {}'.format(r2_test, mse_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at the metrics, what are your main conclusions?   \n",
    "\n",
    "Conclusions here\n",
    "\n",
    "Lasso Alpha 10 produces lowest MSE and highest R2 for testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare number of parameter estimates that are (very close to) 0 for Ridge and Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare with the total length of the parameter space and draw conclusions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of Ridge params almost zero\n",
    "ridge_params_zero = len([param for param in ridge.coef_ if abs(param) < 10**(-10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of Lasso params almost zero\n",
    "lasso_params_zero = len([param for param in lasso.coef_ if abs(param) < 10**(-10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso was very effective to essentially perform variable selection and remove about 25% of the variables from your model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso:  0.2422145328719723\n",
      "Ridge:  0.02768166089965398\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "print('Lasso: ', lasso_params_zero/len(lasso.coef_))\n",
    "print('Ridge: ', ridge_params_zero/len(ridge.coef_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! You now know how to perform Lasso and Ridge regression."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
